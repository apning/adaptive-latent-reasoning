{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb510a8",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.get_options import get_eval_config_from_options\n",
    "from src.model_creation import ModelCreationConfig\n",
    "from src.utils import select_best_device\n",
    "from src.eval import eval_from_config\n",
    "from src.utils import hf_download_and_unjson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc994ab2",
   "metadata": {},
   "source": [
    "Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152dabf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model '''\n",
    "## Specify EITHER model_path_or_repo and (optionally) lora_path_or_repo OR a path or repo which contains a model_creation_config.json\n",
    "model_path_or_repo: str | None = \"Lapisbird/Llama-adaLR-model-latent-6\"\n",
    "lora_path_or_repo: str | None = None\n",
    "## OR\n",
    "mcc_path_or_repo: str | None = None\n",
    "\n",
    "''' Eval '''\n",
    "batch_size: int = 128\n",
    "eval_options: str = \"gsm8k-aug-test/latent_thinking\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a98112",
   "metadata": {},
   "source": [
    "Get model and eval config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_path_or_repo is not None and mcc_path_or_repo is not None:\n",
    "    raise ValueError(\"Specify ONE of model_path_or_repo and mcc_path_or_repo\")\n",
    "\n",
    "if model_path_or_repo is not None:\n",
    "    mcc = ModelCreationConfig(path_or_repo=model_path_or_repo, is_latent=\"latent\" in eval_options or \"latent\" in model_path_or_repo, is_lora=bool(lora_path_or_repo), lora_path_or_repo=lora_path_or_repo)\n",
    "elif mcc_path_or_repo is not None:\n",
    "    mcc_path = Path(mcc_path_or_repo) / \"model_creation_config.json\"\n",
    "    if mcc_path.exists():\n",
    "        mcc = ModelCreationConfig.load_from_json(mcc_path)\n",
    "    else:\n",
    "        mcc = ModelCreationConfig(\n",
    "            **hf_download_and_unjson(mcc_path_or_repo + \"/model_creation_config.json\")\n",
    "        )\n",
    "else:\n",
    "    raise ValueError(\"Not one of model_path_or_repo or mcc_path_or_repo provided\")\n",
    "    \n",
    "model, tokenizer = mcc.get_model_and_tokenizer()\n",
    "\n",
    "eval_config = get_eval_config_from_options(eval_options)\n",
    "\n",
    "device = select_best_device(\"m\")\n",
    "print(\"Using device: \", device)\n",
    "model.to(device)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b3a6d",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5336ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = eval_from_config(model, tokenizer, eval_config, batch_size=batch_size, return_decoded=True)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
