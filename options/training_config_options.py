TRAINING_CONFIG_OPTIONS = {
    ## Data
    "gsm8k-aug": {"data_name": "gsm8k-aug"},
    "gsm8k-aug-nl": {"data_name": "gsm8k-aug-nl"},
    "latent_plus_5_by_1_max_10": {
        "data_mode": "latent",
        "latent_thinking_bias": 5,
        "latent_thinking_factor": 1,
        "max_latent_thinking_steps": 10,
    },
    "latent_plus_6_by_1_max_10": {
        "data_mode": "latent",
        "latent_thinking_bias": 6,
        "latent_thinking_factor": 1,
        "max_latent_thinking_steps": 10,
    },
    "latent_plus_4_by_2_max_8": {
        "data_mode": "latent",
        "latent_thinking_bias": 4,
        "latent_thinking_factor": 2,
        "max_latent_thinking_steps": 8,
    },
    "latent_flat_2": {
        "data_mode": "latent",
        "latent_thinking_factor": 0,
        "min_latent_thinking_steps": 2,
        "max_latent_thinking_steps": 2,
    },
    "latent_flat_6": {
        "data_mode": "latent",
        "latent_thinking_factor": 0,
        "min_latent_thinking_steps": 6,
        "max_latent_thinking_steps": 6,
    },
    "no_cot": {"data_mode": "no cot"},
    "remove_last_reasoning_step": {"remove_last_reasoning_step": True},
    "shift_target_token_one": {"shift_target_token_one": True},
    "mask_latent_reasoning_labels": {"mask_latent_reasoning_labels": True},
    # Warning: multiple options specified via 'additional_trainset_kwargs' will NOT accumulate. They will replace each other
    "remove_negative_answers": {"additional_trainset_kwargs": {"remove_negative_answers": True}},
    "batch_size_4": {"batch_size": 4},
    "batch_size_8": {"batch_size": 8},
    "batch_size_32": {"batch_size": 32},
    "batch_size_64": {"batch_size": 64},
    "batch_size_128": {"batch_size": 128},
    "steps_2k": {"steps": 2000},
    "steps_30k": {"steps": 30000},
    "steps_50k": {"steps": 50000},
    "steps_60k": {"steps": 60000},
    "slice_proportion_75p": {"slice_proportion": 0.75},
    "slice_proportion_85p": {"slice_proportion": 0.85},
    ## Loss
    "codi_loss": {"codi_loss": True},
    "codi_loss_10": {"codi_loss": 10},
    "codi_loss_20": {"codi_loss": 20},
    "codi_loss_100": {"codi_loss": 100},
    "mean_reasoning_loss": {"mean_reasoning_loss": True},
    "mean_reasoning_loss_0p1": {"mean_reasoning_loss": 0.1},
    "mean_reasoning_loss_4": {"mean_reasoning_loss": 4},
    "mean_reasoning_loss_5": {"mean_reasoning_loss": 5},
    "mean_reasoning_loss_10": {"mean_reasoning_loss": 10},
    "mean_reasoning_loss_20": {"mean_reasoning_loss": 20},
    "mean_reasoning_loss_40": {"mean_reasoning_loss": 40},
    "mean_reasoning_loss_100": {"mean_reasoning_loss": 100},
    "intermediate_block_llama_3_12": {"intermediate_block_latent_loss_range": (3, 12)},
    "intermediate_block_gpt2_2_9": {"intermediate_block_latent_loss_range": (2, 9)},
    # Latent loss calc
    "calc_smooth_l1": {"latent_loss_calc_mode": "smooth_l1"},
    "calc_mean_l2": {"latent_loss_calc_mode": "mean_l2"},
    # Latent loss norm
    "norm_layerwise_std": {"latent_loss_norm_mode": "layerwise_std"},
    "norm_layerwise_avg_l2": {"latent_loss_norm_mode": "layerwise_avg_l2"},
    "norm_std": {"latent_loss_norm_mode": "std"},
    "norm_avg_l2": {"latent_loss_norm_mode": "avg_l2"},
    "no_latent_loss_norm": {"latent_loss_norm_mode": "none"},
    ## lr
    "lr_1e-3": {"lr": 1e-3},
    "lr_8e-4": {"lr": 8e-4},
    "lr_3e-4": {"lr": 3e-4},
    "lr_1e-4": {"lr": 1e-4},
    "lr_3e-5": {"lr": 3e-5},
    "lr_1e-5": {"lr": 1e-5},
    "lr_3e-6": {"lr": 3e-6},
    ## Lr scheduler
    "cosine-warmup_900": {"scheduler_name": "cosine", "scheduler_num_warmup_steps": 900},
    ## Max grad norm
    "max_grad_norm_2": {"max_grad_norm": 2.0},
    ## Weight decay
    "weight_decay_0": {"weight_decay": 0},
    "weight_decay_0p1": {"weight_decay": 0.1},
    "no_decay_some_params": {"no_decay_some_params": True},
    ## Val
    "val_period_20": {"val_period": 20},
    "val_period_50": {"val_period": 50},
    "val_period_100": {"val_period": 100},
    "val_period_200": {"val_period": 200},
    "val_period_500": {"val_period": 500},
    "val_period_1k": {"val_period": 1000},
    "val_period_2k": {"val_period": 2000},
    "val_period_5k": {"val_period": 5000},
    ## Saving
    "save_checkpoint_period_100": {"save_checkpoint_period": 100},
    "save_checkpoint_period_200": {"save_checkpoint_period": 200},
    "save_checkpoint_period_500": {"save_checkpoint_period": 500},
    "save_checkpoint_period_1k": {"save_checkpoint_period": 1000},
    "save_checkpoint_period_2k": {"save_checkpoint_period": 2000},
    "save_checkpoint_period_4k": {"save_checkpoint_period": 4000},
    "save_checkpoint_period_5k": {"save_checkpoint_period": 5000},
    "save_checkpoint_period_10k": {"save_checkpoint_period": 10000},
    ## Computational
    "no_gc": {"use_gradient_checkpointing_if_necessary": False, "use_gradient_checkpointing": False},
    "gc": {"use_gradient_checkpointing": True},
    "gc_if_necessary": {"use_gradient_checkpointing_if_necessary": True},
}
